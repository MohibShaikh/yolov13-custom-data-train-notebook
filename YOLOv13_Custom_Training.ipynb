{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# YOLOv13 Custom Dataset Training\n",
        "## Real-Time Object Detection with Hypergraph-Enhanced Adaptive Visual Perception\n",
        "\n",
        "This notebook demonstrates how to train YOLOv13 on custom datasets using the Roboflow structure.\n",
        "\n",
        "**Paper**: [YOLOv13: Real-Time Object Detection with Hypergraph-Enhanced Adaptive Visual Perception](https://github.com/iMoonLab/yolov13)\n",
        "\n",
        "### Key Features:\n",
        "- Hypergraph-enhanced adaptive visual perception\n",
        "- Superior performance compared to YOLOv11/v12\n",
        "- Flash Attention acceleration support\n",
        "- Roboflow integration for seamless dataset management\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "## 1. Environment Setup\n",
        "Install required dependencies including Flash Attention for acceleration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install Flash Attention (Linux x86_64 with CUDA 11)\n",
        "!wget https://github.com/Dao-AILab/flash-attention/releases/download/v2.7.3/flash_attn-2.7.3+cu11torch2.2cxx11abiFALSE-cp311-cp311-linux_x86_64.whl\n",
        "!pip install flash_attn-2.7.3+cu11torch2.2cxx11abiFALSE-cp311-cp311-linux_x86_64.whl\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clone YOLOv13 repository\n",
        "!git clone https://github.com/iMoonLab/yolov13.git\n",
        "%cd yolov13\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install YOLOv13 and dependencies\n",
        "!pip install -r requirements.txt\n",
        "!pip install -e .\n",
        "!pip install roboflow supervision\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 2. Import Required Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import yaml\n",
        "import torch\n",
        "from ultralytics import YOLO\n",
        "from roboflow import Roboflow\n",
        "import supervision as sv\n",
        "from IPython.display import Image, display\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "print(f\"CUDA device count: {torch.cuda.device_count()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"Current CUDA device: {torch.cuda.current_device()}\")\n",
        "    print(f\"CUDA device name: {torch.cuda.get_device_name()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 3. Dataset Preparation with Roboflow\n",
        "### Option A: Download from Roboflow Universe\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize Roboflow (get your API key from https://roboflow.com/)\n",
        "rf = Roboflow(api_key=\"YOUR_ROBOFLOW_API_KEY\")\n",
        "\n",
        "# Download dataset (replace with your project details)\n",
        "project = rf.workspace(\"your-workspace\").project(\"your-project\")\n",
        "dataset = project.version(1).download(\"yolov8\")  # YOLOv13 uses YOLOv8 format\n",
        "\n",
        "dataset_path = dataset.location\n",
        "print(f\"Dataset downloaded to: {dataset_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### Option B: Use Your Local Dataset\n",
        "Ensure your dataset follows this structure:\n",
        "```\n",
        "dataset/\n",
        "├── train/\n",
        "│   ├── images/\n",
        "│   └── labels/\n",
        "├── valid/\n",
        "│   ├── images/\n",
        "│   └── labels/\n",
        "├── test/\n",
        "│   ├── images/\n",
        "│   └── labels/\n",
        "└── data.yaml\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# If using local dataset, specify the path\n",
        "# dataset_path = \"/path/to/your/dataset\"\n",
        "\n",
        "# Verify dataset structure\n",
        "def verify_dataset_structure(dataset_path):\n",
        "    required_dirs = ['train/images', 'train/labels', 'valid/images', 'valid/labels']\n",
        "    for dir_path in required_dirs:\n",
        "        full_path = os.path.join(dataset_path, dir_path)\n",
        "        if os.path.exists(full_path):\n",
        "            print(f\"✓ {dir_path}: {len(os.listdir(full_path))} files\")\n",
        "        else:\n",
        "            print(f\"✗ {dir_path}: Missing\")\n",
        "    \n",
        "    data_yaml = os.path.join(dataset_path, 'data.yaml')\n",
        "    if os.path.exists(data_yaml):\n",
        "        print(f\"✓ data.yaml: Found\")\n",
        "        with open(data_yaml, 'r') as f:\n",
        "            data = yaml.safe_load(f)\n",
        "            print(f\"  Classes: {data.get('nc', 'Not specified')}\")\n",
        "            print(f\"  Names: {data.get('names', 'Not specified')}\")\n",
        "    else:\n",
        "        print(f\"✗ data.yaml: Missing\")\n",
        "\n",
        "verify_dataset_structure(dataset_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 4. Model Selection and Configuration\n",
        "Choose the appropriate YOLOv13 model variant based on your requirements\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# YOLOv13 model variants and their characteristics\n",
        "model_configs = {\n",
        "    'yolov13n': {\n",
        "        'config': 'yolov13n.yaml',\n",
        "        'pretrained': 'yolov13n.pt',\n",
        "        'params': '2.3M',\n",
        "        'map50-95': '37.3',\n",
        "        'speed': '1.25ms',\n",
        "        'description': 'Nano - Fastest, smallest model'\n",
        "    },\n",
        "    'yolov13s': {\n",
        "        'config': 'yolov13s.yaml',\n",
        "        'pretrained': 'yolov13s.pt',\n",
        "        'params': '20.8M',\n",
        "        'map50-95': '48.0',\n",
        "        'speed': '2.98ms',\n",
        "        'description': 'Small - Good balance of speed and accuracy'\n",
        "    },\n",
        "    'yolov13l': {\n",
        "        'config': 'yolov13l.yaml',\n",
        "        'pretrained': 'yolov13l.pt',\n",
        "        'params': '88.4M',\n",
        "        'map50-95': '53.4',\n",
        "        'speed': '8.63ms',\n",
        "        'description': 'Large - High accuracy, moderate speed'\n",
        "    },\n",
        "    'yolov13x': {\n",
        "        'config': 'yolov13x.yaml',\n",
        "        'pretrained': 'yolov13x.pt',\n",
        "        'params': '199.2M',\n",
        "        'map50-95': '54.8',\n",
        "        'speed': '14.67ms',\n",
        "        'description': 'Extra Large - Highest accuracy, slower speed'\n",
        "    }\n",
        "}\n",
        "\n",
        "print(\"YOLOv13 Model Variants:\")\n",
        "print(\"-\" * 80)\n",
        "for model, info in model_configs.items():\n",
        "    print(f\"{model.upper():10} | Params: {info['params']:8} | mAP: {info['map50-95']:5} | Speed: {info['speed']:8} | {info['description']}\")\n",
        "\n",
        "# Select model (change this based on your requirements)\n",
        "selected_model = 'yolov13s'  # Recommended for most use cases\n",
        "model_config = model_configs[selected_model]\n",
        "\n",
        "print(f\"\\nSelected model: {selected_model.upper()}\")\n",
        "print(f\"Description: {model_config['description']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 5. Training Configuration\n",
        "Set up hyperparameters optimized for YOLOv13\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training hyperparameters (optimized for YOLOv13)\n",
        "training_config = {\n",
        "    # Basic settings\n",
        "    'epochs': 100,  # Increase to 300-600 for production\n",
        "    'batch': 16,    # Adjust based on GPU memory (32, 64, 128, 256)\n",
        "    'imgsz': 640,   # Image size\n",
        "    \n",
        "    # Model-specific hyperparameters (from YOLOv13 paper)\n",
        "    'scale': 0.5 if selected_model == 'yolov13n' else 0.9,  # Scaling factor\n",
        "    \n",
        "    # Data augmentation\n",
        "    'mosaic': 1.0,  # Mosaic augmentation probability\n",
        "    'mixup': 0.0 if selected_model == 'yolov13n' else {\n",
        "        'yolov13s': 0.05,\n",
        "        'yolov13l': 0.15,\n",
        "        'yolov13x': 0.2\n",
        "    }.get(selected_model, 0.0),\n",
        "    \n",
        "    'copy_paste': 0.1 if selected_model == 'yolov13n' else {\n",
        "        'yolov13s': 0.15,\n",
        "        'yolov13l': 0.5,\n",
        "        'yolov13x': 0.6\n",
        "    }.get(selected_model, 0.1),\n",
        "    \n",
        "    # Optimization\n",
        "    'optimizer': 'AdamW',\n",
        "    'lr0': 0.01,     # Initial learning rate\n",
        "    'lrf': 0.01,     # Final learning rate\n",
        "    'momentum': 0.937,\n",
        "    'weight_decay': 0.0005,\n",
        "    \n",
        "    # Hardware\n",
        "    'device': '0',   # GPU device (0, 1, 2, 3 or '0,1,2,3' for multi-GPU)\n",
        "    'workers': 8,    # Number of worker threads\n",
        "    \n",
        "    # Validation\n",
        "    'val': True,\n",
        "    'save_period': 10,  # Save checkpoint every N epochs\n",
        "    \n",
        "    # Advanced\n",
        "    'amp': True,     # Automatic Mixed Precision\n",
        "    'half': False,   # Use FP16 inference\n",
        "}\n",
        "\n",
        "print(\"Training Configuration:\")\n",
        "print(\"-\" * 40)\n",
        "for key, value in training_config.items():\n",
        "    print(f\"{key:15}: {value}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 6. Initialize YOLOv13 Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize YOLOv13 model\n",
        "try:\n",
        "    # Try to load pretrained model first\n",
        "    model = YOLO(model_config['pretrained'])\n",
        "    print(f\"✓ Loaded pretrained {selected_model.upper()} model\")\n",
        "except:\n",
        "    # If pretrained model not available, load from config\n",
        "    model = YOLO(model_config['config'])\n",
        "    print(f\"✓ Loaded {selected_model.upper()} model from config (no pretrained weights)\")\n",
        "\n",
        "# Print model info\n",
        "print(f\"\\nModel Summary:\")\n",
        "print(f\"Parameters: {sum(p.numel() for p in model.model.parameters()):,}\")\n",
        "print(f\"Layers: {len(list(model.model.modules()))}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 7. Start Training\n",
        "Train YOLOv13 with hypergraph-enhanced adaptive visual perception\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Start training\n",
        "print(f\"Starting YOLOv13 training on custom dataset...\")\n",
        "print(f\"Model: {selected_model.upper()}\")\n",
        "print(f\"Dataset: {dataset_path}\")\n",
        "print(f\"Epochs: {training_config['epochs']}\")\n",
        "print(f\"Batch size: {training_config['batch']}\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "# Train the model\n",
        "results = model.train(\n",
        "    data=data_yaml_path,\n",
        "    epochs=training_config['epochs'],\n",
        "    batch=training_config['batch'],\n",
        "    imgsz=training_config['imgsz'],\n",
        "    scale=training_config['scale'],\n",
        "    mosaic=training_config['mosaic'],\n",
        "    mixup=training_config['mixup'],\n",
        "    copy_paste=training_config['copy_paste'],\n",
        "    optimizer=training_config['optimizer'],\n",
        "    lr0=training_config['lr0'],\n",
        "    lrf=training_config['lrf'],\n",
        "    momentum=training_config['momentum'],\n",
        "    weight_decay=training_config['weight_decay'],\n",
        "    device=training_config['device'],\n",
        "    workers=training_config['workers'],\n",
        "    val=training_config['val'],\n",
        "    save_period=training_config['save_period'],\n",
        "    amp=training_config['amp'],\n",
        "    project='yolov13_training',\n",
        "    name='custom_dataset',\n",
        "    exist_ok=True\n",
        ")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"TRAINING COMPLETED!\")\n",
        "print(\"=\"*60)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 8. Evaluate Model Performance\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate on validation set\n",
        "print(\"Evaluating model performance...\")\n",
        "metrics = model.val(data=data_yaml_path)\n",
        "\n",
        "# Print key metrics\n",
        "print(f\"\\nValidation Results:\")\n",
        "print(\"-\" * 40)\n",
        "print(f\"mAP50-95: {metrics.box.map:.3f}\")\n",
        "print(f\"mAP50: {metrics.box.map50:.3f}\")\n",
        "print(f\"mAP75: {metrics.box.map75:.3f}\")\n",
        "print(f\"Precision: {metrics.box.mp:.3f}\")\n",
        "print(f\"Recall: {metrics.box.mr:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 9. Export Model for Deployment\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the best trained model\n",
        "best_model = YOLO('yolov13_training/custom_dataset/weights/best.pt')\n",
        "\n",
        "# Export model to different formats\n",
        "print(\"Exporting model for deployment...\")\n",
        "\n",
        "# Export to ONNX (recommended for most deployments)\n",
        "onnx_path = best_model.export(format=\"onnx\", half=False)\n",
        "print(f\"✓ ONNX model exported: {onnx_path}\")\n",
        "\n",
        "# Export to TensorRT (for NVIDIA GPUs)\n",
        "try:\n",
        "    trt_path = best_model.export(format=\"engine\", half=True)\n",
        "    print(f\"✓ TensorRT model exported: {trt_path}\")\n",
        "except:\n",
        "    print(\"⚠ TensorRT export failed (requires TensorRT installation)\")\n",
        "\n",
        "# Export to CoreML (for Apple devices)\n",
        "try:\n",
        "    coreml_path = best_model.export(format=\"coreml\")\n",
        "    print(f\"✓ CoreML model exported: {coreml_path}\")\n",
        "except:\n",
        "    print(\"⚠ CoreML export failed (requires coremltools)\")\n",
        "\n",
        "print(\"\\nModel export completed!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 10. Test Inference and Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test on sample images\n",
        "def test_inference(model, test_images_path, confidence=0.25):\n",
        "    \"\"\"Test model on custom images\"\"\"\n",
        "    if os.path.exists(test_images_path):\n",
        "        image_files = [f for f in os.listdir(test_images_path) \n",
        "                      if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "        \n",
        "        for img_file in image_files[:4]:  # Test on first 4 images\n",
        "            img_path = os.path.join(test_images_path, img_file)\n",
        "            \n",
        "            # Run inference\n",
        "            results = model.predict(img_path, conf=confidence)\n",
        "            \n",
        "            # Display results\n",
        "            for r in results:\n",
        "                im_array = r.plot()  # plot a BGR numpy array of predictions\n",
        "                im_array = cv2.cvtColor(im_array, cv2.COLOR_BGR2RGB)\n",
        "                \n",
        "                plt.figure(figsize=(12, 8))\n",
        "                plt.imshow(im_array)\n",
        "                plt.title(f'YOLOv13 Predictions: {img_file}')\n",
        "                plt.axis('off')\n",
        "                plt.show()\n",
        "                \n",
        "                # Print detection results\n",
        "                if len(r.boxes) > 0:\n",
        "                    print(f\"\\nDetections in {img_file}:\")\n",
        "                    for box in r.boxes:\n",
        "                        cls = int(box.cls)\n",
        "                        conf = float(box.conf)\n",
        "                        class_name = model.names[cls] if cls < len(model.names) else f\"Class_{cls}\"\n",
        "                        print(f\"  {class_name}: {conf:.2f}\")\n",
        "                else:\n",
        "                    print(f\"No detections in {img_file}\")\n",
        "    else:\n",
        "        print(f\"Test images path not found: {test_images_path}\")\n",
        "\n",
        "# Test on validation images\n",
        "test_images_path = os.path.join(dataset_path, 'valid/images')\n",
        "test_inference(best_model, test_images_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 11. Summary and Next Steps\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training summary\n",
        "print(\"🎉 YOLOv13 Custom Training Complete!\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"Model: {selected_model.upper()}\")\n",
        "print(f\"Dataset: {dataset_path}\")\n",
        "print(f\"Training epochs: {training_config['epochs']}\")\n",
        "print(f\"Best model saved: yolov13_training/custom_dataset/weights/best.pt\")\n",
        "print(f\"Last model saved: yolov13_training/custom_dataset/weights/last.pt\")\n",
        "\n",
        "print(\"\\n📊 Performance Metrics:\")\n",
        "try:\n",
        "    print(f\"mAP50-95: {metrics.box.map:.3f}\")\n",
        "    print(f\"mAP50: {metrics.box.map50:.3f}\")\n",
        "    print(f\"Precision: {metrics.box.mp:.3f}\")\n",
        "    print(f\"Recall: {metrics.box.mr:.3f}\")\n",
        "except:\n",
        "    print(\"Metrics not available\")\n",
        "\n",
        "print(\"\\n🚀 Next Steps:\")\n",
        "print(\"1. Fine-tune hyperparameters for better performance\")\n",
        "print(\"2. Increase training epochs (300-600) for production\")\n",
        "print(\"3. Collect more data if mAP is below target\")\n",
        "print(\"4. Deploy model using exported formats (ONNX/TensorRT)\")\n",
        "print(\"5. Monitor model performance in production\")\n",
        "\n",
        "print(\"\\n📚 Key Features of YOLOv13:\")\n",
        "print(\"• Hypergraph-enhanced adaptive visual perception\")\n",
        "print(\"• Superior performance vs YOLOv11/v12\")\n",
        "print(\"• Flash Attention acceleration support\")\n",
        "print(\"• Optimized for real-time object detection\")\n",
        "\n",
        "print(\"\\n📖 Citation:\")\n",
        "print(\"Lei, M., Li, S., Wu, Y., et al. (2025). YOLOv13: Real-Time Object Detection\")\n",
        "print(\"with Hypergraph-Enhanced Adaptive Visual Perception. arXiv:2506.17733\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
